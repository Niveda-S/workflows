{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cytoscape Reactome FI Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Overview\n",
    "--------\n",
    "This example demonstrates a workflow using ReactomeFIViz CyREST API to perform a comparison pathway and network analysis for TCGA BRCA (breast invasive carcinoma) and OV (ovarian serous cystadenocarcinoma) mutation data.\n",
    "\n",
    "The steps executed are as follows:\n",
    "\n",
    "1. Download each cohort mutation annotation file (MAF) from the Broad Firehose WS server.\n",
    "\n",
    "2. Build the two networks using the ReactomeFIViz CyREST API buildFISubNetwork resource.\n",
    "\n",
    "3. Cluster the network into network modules using the cluster resource.\n",
    "\n",
    "4. Perform pair-wise module overlapping analysis.\n",
    "\n",
    "5. Load the Reactome pathways.\n",
    "\n",
    "6. Partition the network modules generated from two networks into the following sets:\n",
    "\n",
    "  * Modules with a significant proportion of genes in common\n",
    "\n",
    "  * Unshared modules for each of the two cancer types\n",
    "\n",
    "7. Perform pathway enrichment analysis for each unshared gene module.\n",
    "\n",
    "8. Export the diagram for an unshared pathway for each cancer type.\n",
    "\n",
    "Prerequisites\n",
    "------------\n",
    "* Python version 2.6 or later\n",
    "\n",
    "* Cytoscape with the latest version of ReactomeFIViz\n",
    "\n",
    "Install the required packages in a Python environment, e.g. in the\n",
    "[Anaconda](https://docs.anaconda.com/anaconda/) virtual environment:\n",
    "\n",
    "    conda create -n cytoscape pandas scipy statsmodels\n",
    "    source activate cytoscape\n",
    "\n",
    "Open Cytoscape before building the networks below. Select `Help > Check for Updates`\n",
    "to ensure that ReactomeFIViz is current.\n",
    "\n",
    "*Note*: Building the networks clears an existing Cytoscape session, if it exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Utility functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python utilities.\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from functools import reduce\n",
    "import requests\n",
    "import tempfile\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from scipy.stats import hypergeom\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MAF download area.\n",
    "# The try-except idiom below, although usually discouraged,\n",
    "# avoids creating a new sandbox for repeated executions.\n",
    "try:\n",
    "    sandbox\n",
    "except NameError:\n",
    "    sandbox = tempfile.mkdtemp()\n",
    "print(\"The downloaded MAF files will be saved to %s.\" % sandbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The REST service url.\n",
    "SERVICE_URL = 'http://localhost:1234'\n",
    "\n",
    "def get_url(*params, **kwargs):\n",
    "    \"\"\"\n",
    "    :param params: the URL path component strings\n",
    "    :option app: the CyREST application name\n",
    "    :return: the REST app URL\n",
    "    \"\"\"\n",
    "    path = [SERVICE_URL]\n",
    "    app = kwargs.get('app')\n",
    "    if app is not None:\n",
    "        path.append(app)\n",
    "    path.append('v1')\n",
    "    path.extend(params)\n",
    "    return '/'.join(path)\n",
    "\n",
    "# Returns the CyREST Reactome FI url.\n",
    "get_fi_url = lambda *params: get_url(*params, app='reactomefiviz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fi_table_response(resp, parsers, index=None):\n",
    "    \"\"\"\n",
    "    Returns the data frame for the given CyREST Reactome\n",
    "    FI response. The response `data` property object must\n",
    "    be a JSON object with properties *tableHeaders* and\n",
    "    *tableContent*. If the response `data` is empty, then\n",
    "    this function returns an empty data frame.\n",
    "    \n",
    "    The required *parsers* dictionary argument associates\n",
    "    a parser with each column.\n",
    "    \n",
    "    :param resp: the CyREST response\n",
    "    :param parsers: the column parser dictionary\n",
    "    :option index: the index column name\n",
    "    :return: the parsed data frame with `tableHeaders` columns,\n",
    "      or an empty data frame if there is no content\n",
    "    \"\"\"\n",
    "    # The response data.\n",
    "    data = resp.json()['data']\n",
    "    if not data:\n",
    "        return pd.DataFrame()\n",
    "    # The cluster data columns.\n",
    "    columns = data.get('tableHeaders')\n",
    "    parsers_list = [parsers[col] for col in columns]\n",
    "    # Parses a cluster content row.\n",
    "    parse_row = lambda row: tuple(parsers_list[i](value) for i, value in enumerate(row))\n",
    "    # The parsed cluster content list.\n",
    "    content = map(parse_row, data['tableContent'])\n",
    "    # Return the cluster data frames.\n",
    "    return pd.DataFrame.from_records(content, index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_maf(cohort, out=None):\n",
    "    \"\"\"\n",
    "    Downloads the MAF file for the given cancer type cohort.\n",
    "    The default output file is `<cohort>.maf` in the\n",
    "    sandbox directory.\n",
    "    \n",
    "    :param cohort: the cancer type cohort name\n",
    "    :option out: the optional output file path\n",
    "    :return: the output file path\n",
    "    \"\"\"\n",
    "    # Download the MAF.\n",
    "    url = 'http://firebrowse.org/api/v1/Analyses/Mutation/MAF'\n",
    "    maf_file = out if out else os.path.join(sandbox, \"%s.maf\" % cohort) \n",
    "    print(\"Downloading the %s MAF file to %s...\" % (cohort, maf_file))\n",
    "    params = dict(format='tsv', cohort=cohort, page_size=2000)\n",
    "    eof = False\n",
    "    page = 1\n",
    "    with open(maf_file, 'w') as f:\n",
    "        while not eof:\n",
    "            params['page'] = page\n",
    "            resp = requests.get(url, params=params)\n",
    "            text = resp.text\n",
    "            if text:\n",
    "                f.write(text)\n",
    "                page = params['page'] = page + 1\n",
    "            else:\n",
    "                eof = True\n",
    "            print('+', end='')\n",
    "    print('')\n",
    "    print(\"MAF file downloaded.\")\n",
    "    return maf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(maf_file, cutoff=.01):\n",
    "    \"\"\"\n",
    "    Builds the network from the given MAF file.\n",
    "    Only gene modules whose sample size exceeds a\n",
    "    threshold are included. The threshold is the\n",
    "    greater of 2 and sample count * cutoff, where\n",
    "    sample count is the total number of MAF samples.\n",
    "    \n",
    "    :param maf_file: the downloaded MAF file\n",
    "    :option cutoff: the minimum proportion of samples\n",
    "    \"\"\"\n",
    "    # Clear the current Cytoscape session, if any.\n",
    "    requests.delete(get_url('session')).ok\n",
    "    # Read the MAF into a data frame.\n",
    "    maf_df = pd.read_csv(maf_file, sep='\\t')\n",
    "    # The number of samples.\n",
    "    sample_cnt = len({tsb for tsb in maf_df.Tumor_Sample_Barcode})\n",
    "    print(\"Sample Count: %d\" % sample_cnt)\n",
    "    sample_cutoff = max(2, int(0.01*sample_cnt))\n",
    "    print(\"Building the FI network with sample cut-off %d...\" % sample_cutoff)\n",
    "    # Build the FI network with 1% sample cut-off.\n",
    "    body = dict(fiVersion='2016', format='MAF', file=maf_file,\n",
    "                enteredGenes='', chooseHomoGenes=False,\n",
    "                userLinkers=False, showUnLinked=False,\n",
    "                fetchFIAnnotations=True,\n",
    "                sampleCutoffValue=sample_cutoff)\n",
    "    requests.post(get_fi_url('buildFISubNetwork'), json=body)\n",
    "    print()\n",
    "    print(\"The FI network is loaded to Cytoscape.\")\n",
    "    return maf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cluster content value parsers.\n",
    "cluster_parsers = {\n",
    "    'Module': int, 'Nodes in Module': int, 'Node Percentage': float,\n",
    "    'Samples in Module': int, 'Sample Percentage': float,\n",
    "    'Node List': lambda s: s.split(',')\n",
    "}\n",
    "\n",
    "def cluster():\n",
    "    \"\"\"\n",
    "    Cluster the network currently displayed in Cytoscape into\n",
    "    gene modules.\n",
    "    \n",
    "    :return: a data frame with index *Module* and columns\n",
    "      *module_size* and *genes*\n",
    "    \"\"\"\n",
    "    # Cluster the currently displayed network.\n",
    "    print(\"Clustering the FI network...\")\n",
    "    resp = requests.get(get_fi_url('cluster'))\n",
    "    # Parse the response JSON into a data frame.\n",
    "    parsed = parse_fi_table_response(resp, parsers=cluster_parsers, index='Module')\n",
    "    # Rename the columns.\n",
    "    renamed = parsed.rename(columns={'Node List': 'genes', 'Nodes in Module': 'module_size'})\n",
    "    # Retain only the 'genes' and 'size' columns.\n",
    "    sliced = renamed.loc[:, ['module_size', 'genes']]\n",
    "    print(\"The cluster table is available in Cytoscape.\")\n",
    "    return sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(cohort):\n",
    "    \"\"\"\n",
    "    Prepares the given cancer type cohort for analysis.\n",
    "    \n",
    "    :param cohort: the cancer type cohort name\n",
    "    :return: the clustered data frame\n",
    "    \"\"\"\n",
    "    # Clear the current Cytoscape session, if any.\n",
    "    try:\n",
    "        requests.delete(get_url('session')).ok\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Error: Connection refused: is Cytoscape started?\")\n",
    "        raise\n",
    "    maf_file = os.path.join(sandbox, \"%s.maf\" % cohort)\n",
    "    # Download the MAF, if necessary.\n",
    "    if (not os.path.exists(maf_file)):\n",
    "        download_maf(cohort, out=maf_file)\n",
    "    # Build the network.\n",
    "    build_network(maf_file)\n",
    "    # Cluster into gene modules.\n",
    "    return cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_pvalue(N, gs1, gs2):\n",
    "    \"\"\"\n",
    "    :param N: the number of background genes\n",
    "    :param gs1: the first gene set\n",
    "    :param gs2: the second gene set\n",
    "    :return: the probability of gene set overlap from\n",
    "      a background population of *N* genes\n",
    "    \"\"\"\n",
    "    # The shared genes.\n",
    "    overlap = set(gs1).intersection(set(gs2))\n",
    "    # The hypergeometric distribution parameters.\n",
    "    k = len(overlap) - 1\n",
    "    n1 = len(gs1)\n",
    "    n2 = len(gs2)\n",
    "    # Return the overlap probability.\n",
    "    return hypergeom.sf(k, N, n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_module_size(inputs, max_len=None):\n",
    "    \"\"\"\n",
    "    Returns subsets of the given data frames with module\n",
    "    count no greater than a threshold value. The threshold\n",
    "    is given by the *max_len* option, with default the\n",
    "    minimum module count of the input data frames.\n",
    "    The module selection criterion is a gene module size\n",
    "    which ensures that no more than *max_len* modules are\n",
    "    selected from each data frame.\n",
    "    \n",
    "    :param inputs: the input {name: data frame} dictionary\n",
    "    :option max_len: the module count threshold\n",
    "    :return: the corresponding filtered data frames\n",
    "    \"\"\"\n",
    "    # The size cutoff.\n",
    "    n = max_len if max_len else min(len(d) for df in modules)\n",
    "    # The n largest data frames.\n",
    "    largest = [df.module_size.nlargest(n) for df in inputs.values()]\n",
    "    cutoff = max(ds.iloc[n - 1] for ds in largest)\n",
    "    return {name: df.loc[df.module_size.ge(cutoff), :]\n",
    "            for name, df in inputs.items()}\n",
    "\n",
    "def slice_on_node_list(name, df):\n",
    "    \"\"\"\n",
    "    Slices the given data frame vertically on the *genes* column.\n",
    "    Renames the *Module* index to the given name and the *genes*\n",
    "    column to '<name> Genes', e.g. 'BRCA Genes' for *name* 'BRCA'.\n",
    "    \n",
    "    :param name: the cancer type cohort name\n",
    "    :param df: the gene modules data frame\n",
    "    :return: the data frame with renamed index and column\n",
    "    \"\"\"\n",
    "    rename_dict = {'genes': \"%s Genes\" % name}\n",
    "    sliced = df.loc[:, ['genes']].rename(columns=rename_dict)\n",
    "    sliced.index.names = [name]\n",
    "    return sliced\n",
    "\n",
    "def cartesian(df1, df2):\n",
    "    \"\"\"\n",
    "    Takes the cartesian product of the input data frames.\n",
    "    The resulting data frame has a mult-index with levels\n",
    "    given by the respective input data frame indexes.\n",
    "    \n",
    "    :param df1: the first data frame\n",
    "    :param df2: the second data frame\n",
    "    :return: the cartesian product of the input data frames\n",
    "    \"\"\"\n",
    "    rows = itertools.product(df1.iterrows(), df2.iterrows())\n",
    "    values = (left.append(right) for (_, left), (_, right) in rows)\n",
    "    indexes = [df1.index, df2.index]\n",
    "    index_names = [index.name for index in indexes]\n",
    "    index_values = [index.values for index in indexes]\n",
    "    multi_index = pd.MultiIndex.from_product(index_values, names=index_names)\n",
    "    return pd.DataFrame(values, index=multi_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_overlap(n, cross):\n",
    "    \"\"\"\n",
    "    Calculates the pair-wise overlap p-value for the given\n",
    "    gene module cross-product.\n",
    "    The return value is the cross-product augmented with\n",
    "    two columns:\n",
    "    * _uncorrected_pvalue_ - the hypergeometric test p value\n",
    "    * _corrected_pvalue_ - the p-values corrected for\n",
    "      multiple tests\n",
    "    \n",
    "    :param n: the background gene count\n",
    "    :param cross: the cross-product data frame\n",
    "    :return: the augmented data frame\n",
    "    \"\"\"\n",
    "    # Calculates the overlap p-value.\n",
    "    pvals = cross.agg(lambda row: overlap_pvalue(n, *row.values), axis=1)\n",
    "    # Augment the cross-product with the uncorrrected p-values.\n",
    "    overlap_df = cross.assign(uncorrected_pvalue=pvals)\n",
    "    # Correct the given p-values for multiple comparison hypothesis\n",
    "    # testing by applying the Benjaminiâ€“Hochberg FDR procedure.\n",
    "    _, corrected, _, _ = multipletests(pvals.values, method='fdr_bh')\n",
    "    overlap_df['corrected_pvalue'] = corrected\n",
    "    return overlap_df\n",
    "\n",
    "def unshared_series(df, shared_index):\n",
    "    unshared_index = set(df.index.values) - set(shared_index)\n",
    "    return df.loc[unshared_index, :].genes\n",
    "\n",
    "def partition_shared(overlap_df, inputs, cutoff=.01):\n",
    "    \"\"\"\n",
    "    Partitions the gene modules into three data series:\n",
    "    * A shared data series for gene modules with significant\n",
    "      overlap\n",
    "    * Unshared data series for each cancer type\n",
    "    The shared data series has a multi-index of the cancer types.\n",
    "    The unshared data series has index `Module`.\n",
    "    Each data series values are gene lists.\n",
    "    The gene modules are filtered by p-value (see *cutoff* option below).\n",
    "    \n",
    "    :param overlap_df: the input data frame is the BRCA x OV\n",
    "      module cartesian cross-product augmented with a\n",
    "      pair-wise overlap *corrected_pvalue*\n",
    "    :param inputs: the {name: <data frame>} inputs\n",
    "    :option cutoff: the corrected p-value cutoff value which\n",
    "      determines a shared module (default .01)\n",
    "    :return the {'shared': <series>, 'unshared': {name: <series>}}\n",
    "      data series dictionary for each *name* in inputs\n",
    "    \"\"\"\n",
    "    # The shared gene modules have corrected p-value < cutoff\n",
    "    criterion = overlap_df['corrected_pvalue'].lt(cutoff)\n",
    "    shared_df = overlap_df.loc[criterion]\n",
    "    # Merge the shared genes.\n",
    "    gs_cols = [\"%s Genes\" % name for name in inputs.keys()]\n",
    "    ds1, ds2 = [shared_df[name] for name in gs_cols]\n",
    "    merge = lambda gs1, gs2: set(gs1) | set(gs2)\n",
    "    shared_ds = ds1.combine(ds2, merge)\n",
    "    print(\"Shared module count: %d\" % shared_ds.size)\n",
    "    shared_idx_values = [set(values)\n",
    "                         for values in zip(*shared_ds.index.values)]\n",
    "    shared_idx_names = shared_ds.index.names\n",
    "    shared_idx_dict = {name: shared_idx_values[i]\n",
    "                       for i, name in enumerate(shared_idx_names)}\n",
    "    unshared = {name: unshared_series(df, shared_idx_dict[name])\n",
    "                for name, df in inputs.items()}\n",
    "    for name, ds in unshared.items():\n",
    "           print(\"Unshared %s module count: %d\" % (name, ds.size))\n",
    "    return dict(shared=shared_ds, unshared=unshared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_overlap(n, inputs, max_len=None):\n",
    "    \"\"\"\n",
    "    Performs pair-wise overlap analysis on the given cluster\n",
    "    data frames.\n",
    "    \n",
    "    :param n: the background gene count\n",
    "    :param inputs: the {name: data frame} inputs dictionary\n",
    "    :option max_len: option specifies an upper bound on the\n",
    "      number of modules to be included in the overlap from\n",
    "      each cancer type in the overlap (see filter_on_module_size) \n",
    "    :return the {'shared': <series>, 'unshared': {name: <series>}}\n",
    "      data series dictionary for each *name* in inputs\n",
    "    \"\"\"\n",
    "    # Select the largest modules.\n",
    "    filtered = filter_on_module_size(inputs, max_len=max_len)\n",
    "    # Prep pair-wise analysis by taking the cartesian product\n",
    "    # of the two filtered data frames renamed with unique columns.\n",
    "    sliced = {name: slice_on_node_list(name, df) for name, df in inputs.items()}\n",
    "    cross_df = cartesian(*sliced.values())\n",
    "    overlap_df = append_overlap(n, cross_df)\n",
    "    return partition_shared(overlap_df, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_parsers = {\n",
    "    'ReactomePathway': lambda p: p,\n",
    "    'RatioOfProteinInPathway': float,\n",
    "    'NumberOfProteinInPathway': int,\n",
    "    'ProteinFromGeneSet': int,\n",
    "    'P-value': float,\n",
    "    'FDR': float,\n",
    "    'HitGenes': lambda s: s.split(',')\n",
    "}\n",
    "\n",
    "def enrich_genes(genes):\n",
    "    \"\"\"\n",
    "    Perform pathway enrichment analysis on the given genes.\n",
    "    \n",
    "    :param genes: the gene list or set to enrich\n",
    "    :return: the result data frame, or an empty data frame\n",
    "      if the genes could not be enriched\n",
    "    \"\"\"\n",
    "    data = ','.join(genes)\n",
    "    # Perform the Reactome enrichment analysis.\n",
    "    resp = requests.post(get_fi_url('ReactomePathwayEnrichment'),\n",
    "                         data=data)\n",
    "    resp.raise_for_status()\n",
    "    return parse_fi_table_response(resp, enrichment_parsers,\n",
    "                                   index='ReactomePathway')\n",
    "\n",
    "def enrich_modules(modules, cutoff=.001):\n",
    "    \"\"\"\n",
    "    Perform pathway enrichment on the given gene modules.\n",
    "    \n",
    "    :param modules: the gene modules to enrich\n",
    "    :option cutoff: the FDR cut-off (default .001)\n",
    "    :return: the significant enriched pathways\n",
    "    \"\"\"\n",
    "    enrichments = [enrich_genes(ds) for ds in modules]\n",
    "    enrichments = [e for e in enrichments if not e.empty]\n",
    "    # Select the pathway (as index) and FDR where FDR < cutoff.\n",
    "    filtered = [e.FDR.loc[e.FDR.lt(cutoff)] for e in enrichments]\n",
    "    # Collect all significant shared pathways.\n",
    "    return set(pd.concat(filtered).index.values)\n",
    "\n",
    "def enrich_partition(partition):\n",
    "    \"\"\"\n",
    "    Performs pathway enrichment on the gene module partition.\n",
    "    \n",
    "    :param partition: the {shared, unshared} partition dictionary\n",
    "    \"\"\"\n",
    "    print(\"Enriching the shared modules...\")\n",
    "    shared = enrich_modules(partition['shared'])\n",
    "    print(\"Significant shared enriched pathway count: %d\" % len(shared))\n",
    "    unshared = set()\n",
    "    for name, ds in partition['unshared'].items():\n",
    "        print(\"Enriching the unshared %s modules...\" % name)\n",
    "        enriched = enrich_modules(ds)\n",
    "        print(\"Significant unshared %s enriched pathway count: %d\" %\n",
    "              (name, len(enriched)))\n",
    "        unshared.update(enriched)\n",
    "    print(\"Significant unshared pathway count: %d\" % len(unshared))\n",
    "\n",
    "def distinct_pathways(inputs):\n",
    "    \"\"\"\n",
    "    Enriches the given gene set data series and removes the common pathways.\n",
    "    \n",
    "    :param inputs: the input {name: data series} dictionary\n",
    "    :return: the (name: pathways} dictionary\n",
    "    \"\"\"\n",
    "    collect_genes = lambda ds: set().union(*ds.values)\n",
    "    enrich = lambda ds: enrich_genes(collect_genes(ds)).index.get_values()\n",
    "    enriched = {name: set(enrich(ds)) for name, ds in inputs.items()}\n",
    "    # The genes in common.\n",
    "    # This is a rare case where python reduce is clearer than a for loop. \n",
    "    common = reduce(lambda s1, s2: s1.intersection(s2), enriched.values())\n",
    "    # Return the distinct pathways.\n",
    "    return {name: p - common for name, p in enriched.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarchy_node(pathway, hierarchy):\n",
    "    \"\"\"\n",
    "    Returns the Reactome hierarchy node for the given pathway.\n",
    "    \n",
    "    :param pathway: the pathway to check\n",
    "    :param hierarchy: the Reactome pathway hierarchy to check\n",
    "    :return: the hierarchy node\n",
    "    \"\"\"\n",
    "    if hierarchy['name'] == pathway:\n",
    "        return hierarchy\n",
    "    children = hierarchy.get('children')\n",
    "    if children:\n",
    "        for subtree in children:\n",
    "            target = get_hierarchy_node(pathway, subtree)\n",
    "            if target:\n",
    "                return target\n",
    "\n",
    "def export_diagram(db_id, pathway, out_dir=None):\n",
    "    \"\"\"\n",
    "    Exports a diagram PDF for the given pathway. The PDF\n",
    "    is placed in the target output directory. The file name\n",
    "    capitalizes the pathway name and removes spaces and\n",
    "    punctuation, e.g. `DekBindsTfap2aHomodimers`.\n",
    "    \n",
    "    :param db_id: the Reactome pathway db id\n",
    "    :param pathway: the pathway name to export\n",
    "    :param out_dir: the target directory (default current directory)\n",
    "    :return: the exported PDF file name\n",
    "    \"\"\"\n",
    "    if not out_dir:\n",
    "        out_dir = os.getcwd()\n",
    "    base_name = re.sub(r'[^\\w]', '', pathway)\n",
    "    file_name = os.path.join(out_dir, \"%s.pdf\" % base_name)\n",
    "    body = dict(dbId=db_id, pathwayName=pathway, fileName=file_name)\n",
    "    requests.post(get_fi_url('exportPathwayDiagram'), json=body)\n",
    "    print(\"Exported pathway '%s' to %s.\" % (pathway, file_name))\n",
    "    return file_name\n",
    "\n",
    "def export_first_pathway_diagram(pathways, hierarchy):\n",
    "    \"\"\"\n",
    "    Exports the diagram for the first pathway which has one.\n",
    "    \n",
    "    :param pathways: the pathways to check\n",
    "    :param hierarchy: the Reactome pathway hierarchy to check\n",
    "    :return: the exported diagram file name\n",
    "    \"\"\"\n",
    "    for pathway in pathways:\n",
    "        node = get_hierarchy_node(pathway, hierarchy)\n",
    "        if node and node['hasDiagram']:\n",
    "            db_id = node['dbId']\n",
    "            pathway = node['name']\n",
    "            return export_diagram(db_id, pathway, sandbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Prepare the network**\n",
    "\n",
    "* Download the cohort mutation annotation file (MAF) from the Broad Firehose WS server.\n",
    "\n",
    "* Build the network using the ReactomeFIViz CyREST API buildFISubNetwork resource.\n",
    "\n",
    "* Cluster the network into network modules using the cluster resource.\n",
    "\n",
    "(cf. User Guide\n",
    "[Mutation Analysis](http://wiki.reactome.org/index.php?title=ReactomeFIViz&redirect=no#Gene_Set.2FMutation_Analysis)\n",
    "step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the BRCA cohort for analysis.\n",
    "# This takes a while.\n",
    "brca_df = prepare('BRCA')\n",
    "print(\"BRCA module count: %d\" % brca_df.index.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Result*: Cytoscape displays the BRCA FI network\n",
    "and clustered gene modules table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the OV cohort for analysis.\n",
    "# This takes a while.\n",
    "ov_df = prepare('OV')\n",
    "print(\"OV module count: %d\" % ov_df.index.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Result*: Cytoscape displays the OV FI network\n",
    "and clustered gene modules table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Partition the modules**\n",
    "\n",
    "* Perform pair-wise module overlapping analysis.\n",
    "\n",
    "* Partition the network modules into the following sets:\n",
    "\n",
    "  * Modules with a significant proportion of genes in common\n",
    "\n",
    "  * Unshared modules for each of the two cancer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of background genes N is the Reactome FI\n",
    "# network gene size.\n",
    "BACKGROUND_GENE_CNT = 12283\n",
    "\n",
    "# The analysis input.\n",
    "inputs = {'BRCA': brca_df, 'OV': ov_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover modules with significant overlap.\n",
    "partition = analyse_overlap(BACKGROUND_GENE_CNT, inputs, max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Load the Reactome pathways.**\n",
    "\n",
    "(cf. the User Guide\n",
    "[Explore Pathways](http://wiki.reactome.org/index.php?title=ReactomeFIViz&redirect=no#Explore_Reactome_Pathways)\n",
    "step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(get_fi_url('pathwayTree'))\n",
    "reactome_tree = resp.json()['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Result*: Reactome heirarchy displayed in the Cytoscape Control Panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform pathway enrichment on the gene modules.\n",
    "enrich_partition(partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Result*: Enrichment results are successively displayed in the Cytoscape Table Panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Perform pathway enrichment on the unshared gene modules.**\n",
    "\n",
    "(cf. User Guide\n",
    "[Enrichment Analysis](http://wiki.reactome.org/index.php?title=ReactomeFIViz&redirect=no#Pathway_Enrichment_Analysis)\n",
    "step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich the unshared genes.\n",
    "distinct = distinct_pathways(partition['unshared'])\n",
    "for name, pathways in distinct.items():\n",
    "    print(\"%s-only enrichment pathway count: %d\" % (name, len(pathways)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition['unshared']['BRCA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Export an unshared pathway diagram for each cancer type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export one diagram per cancer type.\n",
    "for name, pathways in distinct.items():\n",
    "    print(\"Exporting a %s pathway...\" % name)\n",
    "    export_first_pathway_diagram(pathways, reactome_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
