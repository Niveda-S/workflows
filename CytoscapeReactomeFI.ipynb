{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cytoscape Reactome FI Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Overview\n",
    "--------\n",
    "This example demonstrates a workflow using ReactomeFIViz CyREST API to perform a comparison pathway and network analysis for TCGA BRCA (breast invasive carcinoma) and OV (ovarian serous cystadenocarcinoma) mutation data.\n",
    "\n",
    "The steps executed are as follows:\n",
    "\n",
    "1. Download each cohort mutation annotation file (MAF) from the Broad Firehose WS server.\n",
    "\n",
    "2. Build the two networks using the ReactomeFIViz CyREST API buildFISubNetwork resource.\n",
    "\n",
    "3. Cluster the network into network modules using the cluster resource.\n",
    "\n",
    "4. Perform pair-wise module overlapping analysis.\n",
    "\n",
    "5. Load the Reactome pathways.\n",
    "\n",
    "6. Partition the network modules generated from two networks into the following sets:\n",
    "\n",
    "  * Modules with a significant proportion of genes in common\n",
    "\n",
    "  * Unshared modules for each of the two cancer types\n",
    "\n",
    "7. Perform pathway enrichment analysis for each unshared gene module.\n",
    "\n",
    "8. Export the diagram for an unshared pathway for each cancer type.\n",
    "\n",
    "Prerequisites\n",
    "------------\n",
    "* Python version 2.6 or later\n",
    "\n",
    "* Cytoscape with the latest version of ReactomeFIViz\n",
    "\n",
    "Install the required packages in a Python environment, e.g. in the\n",
    "[Anaconda](https://docs.anaconda.com/anaconda/) virtual environment:\n",
    "\n",
    "    conda create -n cytoscape pip pandas scipy statsmodels\n",
    "    source activate cytoscape\n",
    "\n",
    "Open Cytoscape before building the networks below. Select `Help > Check for Updates`\n",
    "to ensure that ReactomeFIViz is current.\n",
    "\n",
    "*Note*: Building the networks clears an existing Cytoscape session, if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python utilities.\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import shutil\n",
    "import itertools\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from scipy.stats import hypergeom\n",
    "import numpy as np\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "if sys.version_info < (3,0):\n",
    "    from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MAF download area.\n",
    "# The try-except idiom below, although usually discouraged,\n",
    "# avoids creating a new sandbox for repeated executions.\n",
    "try:\n",
    "    sandbox\n",
    "except NameError:\n",
    "    sandbox = tempfile.mkdtemp()\n",
    "print(\"The downloaded MAF files will be saved to %s.\" % sandbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The REST service url.\n",
    "SERVICE_URL = 'http://localhost:1234'\n",
    "\n",
    "def get_url(*params, **kwargs):\n",
    "    \"\"\"\n",
    "    :param params: the URL path component strings\n",
    "    :option app: the CyREST application name\n",
    "    :return: the REST app URL\n",
    "    \"\"\"\n",
    "    path = [SERVICE_URL]\n",
    "    app = kwargs.get('app')\n",
    "    if app is not None:\n",
    "        path.append(app)\n",
    "    path.append('v1')\n",
    "    path.extend(params)\n",
    "    return '/'.join(path)\n",
    "\n",
    "# Returns the CyREST Reactome FI url.\n",
    "get_fi_url = lambda *params: get_url(*params, app='reactomefiviz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fi_table_response(resp, parsers, index=None):\n",
    "    \"\"\"\n",
    "    Returns the data frame for the given CyREST Reactome\n",
    "    FI response.  The response must contain a `data`\n",
    "    property object with content:\n",
    "    \n",
    "        {tableHeaders, tableHeaders, tableContent}.\n",
    "    \n",
    "    The required *parsers* dictionary argument associates\n",
    "    a parser with each column.\n",
    "    \n",
    "    :param resp: the CyREST response\n",
    "    :param parsers: the column parser dictionary\n",
    "    :option index: the index column name\n",
    "\"\"\"\n",
    "    # The cluster response data.\n",
    "    data = resp.json()['data']\n",
    "    # The cluster data columns.\n",
    "    columns = data['tableHeaders']\n",
    "    parsers_list = [parsers[col] for col in columns]\n",
    "    # Parses a cluster content row.\n",
    "    parse_row = lambda row: tuple(parsers_list[i](value) for i, value in enumerate(row))\n",
    "    # The parsed cluster content list.\n",
    "    content = map(parse_row, data['tableContent'])\n",
    "    # Return the cluster data frames.\n",
    "    return pd.DataFrame.from_records(content, index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_maf(cohort, out=None):\n",
    "    \"\"\"\n",
    "    Downloads the MAF file for the given cancer type cohort.\n",
    "    The default output file is `<cohort>.maf` in the\n",
    "    sandbox directory.\n",
    "    \n",
    "    :param cohort: the cancer type cohort name\n",
    "    :option out: the optional output file path\n",
    "    :return: the output file path\n",
    "    \"\"\"\n",
    "    # Download the MAF.\n",
    "    url = 'http://firebrowse.org/api/v1/Analyses/Mutation/MAF'\n",
    "    maf_file = out if out else os.path.join(sandbox, \"%s.maf\" % cohort) \n",
    "    print(\"Downloading the %s MAF file to %s...\" % (cohort, maf_file))\n",
    "    params = dict(format='tsv', cohort=cohort, page_size=2000)\n",
    "    eof = False\n",
    "    page = 1\n",
    "    with open(maf_file, 'w') as f:\n",
    "        while not eof:\n",
    "            params['page'] = page\n",
    "            resp = requests.get(url, params=params)\n",
    "            text = resp.text\n",
    "            if text:\n",
    "                f.write(text)\n",
    "                page = params['page'] = page + 1\n",
    "            else:\n",
    "                eof = True\n",
    "            print('+', end='')\n",
    "    print(\"MAF file downloaded.\")\n",
    "    return maf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(maf_file, cutoff=.01):\n",
    "    \"\"\"\n",
    "    Builds the network from the given MAF file.\n",
    "    Only gene modules whose sample size exceeds a\n",
    "    threshold are included. The threshold is the\n",
    "    greater of 2 and sample count * cutoff, where\n",
    "    sample count is the total number of MAF samples.\n",
    "    \n",
    "    :param maf_file: the downloaded MAF file\n",
    "    :option cutoff: the minimum proportion of samples\n",
    "    \"\"\"\n",
    "    # Clear the current Cytoscape session, if any.\n",
    "    requests.delete(get_url('session')).ok\n",
    "    # Read the MAF into a data frame.\n",
    "    maf_df = pd.read_csv(maf_file, sep='\\t')\n",
    "    # The number of samples.\n",
    "    sample_cnt = len({tsb for tsb in maf_df.Tumor_Sample_Barcode})\n",
    "    print(\"Sample Count: %d\" % sample_cnt)\n",
    "    sample_cutoff = max(2, int(0.01*sample_cnt))\n",
    "    print(\"Building the FI network with sample cut-off %d...\" % sample_cutoff)\n",
    "    # Build the FI network with 1% sample cut-off.\n",
    "    body = dict(fiVersion='2016', format='MAF', file=maf_file,\n",
    "                enteredGenes='', chooseHomoGenes=False,\n",
    "                userLinkers=False, showUnLinked=False,\n",
    "                fetchFIAnnotations=True,\n",
    "                sampleCutoffValue=sample_cutoff)\n",
    "    requests.post(get_fi_url('buildFISubNetwork'), json=body)\n",
    "    print()\n",
    "    print(\"The FI network is loaded to Cytoscape.\")\n",
    "    return maf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cluster content value parsers.\n",
    "cluster_parsers = {\n",
    "    'Module': int, 'Nodes in Module': int, 'Node Percentage': float,\n",
    "    'Samples in Module': int, 'Sample Percentage': float,\n",
    "    'Node List': lambda s: s.split(',')\n",
    "}\n",
    "\n",
    "def cluster():\n",
    "    \"\"\"\n",
    "    Cluster the network currently displayed in Cytoscape into\n",
    "    gene modules.\n",
    "    \n",
    "    :return: a data frame with index *Module* and columns\n",
    "      *module_size* and *genes*\n",
    "    \"\"\"\n",
    "    # Cluster the currently displayed network.\n",
    "    print(\"Clustering the FI network...\")\n",
    "    resp = requests.get(get_fi_url('cluster'))\n",
    "    # Parse the response JSON into a data frame.\n",
    "    parsed = parse_fi_table_response(resp, parsers=cluster_parsers, index='Module')\n",
    "    # Rename the columns.\n",
    "    renamed = parsed.rename(columns={'Node List': 'genes', 'Nodes in Module': 'module_size'})\n",
    "    # Retain only the 'genes' and 'size' columns.\n",
    "    sliced = renamed.loc[:, ['module_size', 'genes']]\n",
    "    print(\"The cluster table is available in Cytoscape.\")\n",
    "    return sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(cohort):\n",
    "    \"\"\"\n",
    "    Prepares the given cancer type cohort for analysis.\n",
    "    \n",
    "    :param cohort: the cancer type cohort name\n",
    "    :return: the clustered data frame\n",
    "    \"\"\"\n",
    "    # Clear the current Cytoscape session, if any.\n",
    "    try:\n",
    "        requests.delete(get_url('session')).ok\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Error: Connection refused: is Cytoscape started?\")\n",
    "        raise\n",
    "    maf_file = os.path.join(sandbox, \"%s.maf\" % cohort)\n",
    "    # Download the MAF, if necessary.\n",
    "    if (not os.path.exists(maf_file)):\n",
    "        download_maf(cohort, out=maf_file)\n",
    "    # Build the network.\n",
    "    build_network(maf_file)\n",
    "    # Cluster into gene modules.\n",
    "    return cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_pvalue(N, gs1, gs2):\n",
    "    \"\"\"\n",
    "    :param N: the number of background genes\n",
    "    :param gs1: the first gene set\n",
    "    :param gs2: the second gene set\n",
    "    :return: the probability of gene set overlap from\n",
    "      a background population of *N* genes\n",
    "    \"\"\"\n",
    "    # The shared genes.\n",
    "    overlap = set(gs1).intersection(set(gs2))\n",
    "    M = len(overlap)\n",
    "    n1 = len(gs1)\n",
    "    n2 = len(gs2)\n",
    "    # The CDF of complete overlap.\n",
    "    kmax = min(n1, n2)\n",
    "    cdf_max = hypergeom.cdf(kmax, N, n1, n2)\n",
    "    # The CDF of the observed overlap.\n",
    "    kmin = M - 1\n",
    "    cdf_obs = hypergeom.cdf(kmin, N, n1, n2)\n",
    "    # Return the overlap probability.\n",
    "    return cdf_max - cdf_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_on_module_size(inputs, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns subsets of the given data frames with module\n",
    "    count no greater than a threshold value. The threshold\n",
    "    is given by the *max_len* option, with default the\n",
    "    minimum module count of the input data frames.\n",
    "    The module selection criterion is a gene module size\n",
    "    which ensures that no more than *max_len* modules are\n",
    "    selected from each data frame.\n",
    "    \n",
    "    :param input: the input {name: data frame} dictionary\n",
    "    :return: the corresponding filtered data frames\n",
    "    \"\"\"\n",
    "    # The size cutoff.\n",
    "    max_len_opt = kwargs.get('max_len', None)\n",
    "    n = max_len_opt or min(len(d) for df in modules)\n",
    "    # The n largest data frames.\n",
    "    largest = [df.module_size.nlargest(n) for df in inputs.values()]\n",
    "    cutoff = max(ds.iloc[n - 1] for ds in largest)\n",
    "    return {name: df.loc[df.module_size.ge(cutoff), :]\n",
    "            for name, df in inputs.items()}\n",
    "\n",
    "def slice_on_node_list(name, df):\n",
    "    \"\"\"\n",
    "    Slices the given data frame vertically on the *genes* column.\n",
    "    Renames the *Module* index to the given name and the *genes*\n",
    "    column to '<name> Genes', e.g. 'BRCA Genes' for *name* 'BRCA'.\n",
    "    \n",
    "    :param name: the cancer type cohort name\n",
    "    :param df: the gene modules data frame\n",
    "    :return: the data frame with renamed index and column\n",
    "    \"\"\"\n",
    "    rename_dict = {'genes': \"%s Genes\" % name}\n",
    "    sliced = df.loc[:, ['genes']].rename(columns=rename_dict)\n",
    "    sliced.index.names = [name]\n",
    "    return sliced\n",
    "\n",
    "def cartesian(df1, df2):\n",
    "    \"\"\"\n",
    "    Takes the cartesian product of the input data frames.\n",
    "    The resulting data frame has a mult-index with levels\n",
    "    given by the respective input data frame indexes.\n",
    "    \n",
    "    :param df1: the first data frame\n",
    "    :param df2: the second data frame\n",
    "    :return: the cartesian product of the input data frames\n",
    "    \"\"\"\n",
    "    rows = itertools.product(df1.iterrows(), df2.iterrows())\n",
    "    values = (left.append(right) for (_, left), (_, right) in rows)\n",
    "    indexes = [df1.index, df2.index]\n",
    "    index_names = [index.name for index in indexes]\n",
    "    index_values = [index.values for index in indexes]\n",
    "    multi_index = pd.MultiIndex.from_product(index_values, names=index_names)\n",
    "    return pd.DataFrame(values, index=multi_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_overlap(n, cross):\n",
    "    \"\"\"\n",
    "    Calculates the pair-wise overlap p-value for the given\n",
    "    gene module cross-product.\n",
    "    The return value is the cross-product augmented with\n",
    "    two columns:\n",
    "    * _uncorrected_pvalue_ - the hypergeometric test p value\n",
    "    * _corrected_pvalue_ - the p-values corrected for\n",
    "      multiple tests\n",
    "    \n",
    "    :param n: the background gene count\n",
    "    :param cross: the cross-product data frame\n",
    "    :return: the augmented data frame\n",
    "    \"\"\"\n",
    "    # Calculates the overlap p-value.\n",
    "    pvals = cross.agg(lambda row: overlap_pvalue(n, *row.values), axis=1)\n",
    "    # Augment the cross-product with the uncorrrected p-values.\n",
    "    overlap_df = cross.assign(uncorrected_pvalue=pvals)\n",
    "    # Correct the given p-values for multiple comparison hypothesis\n",
    "    # testing by applying the Benjamini–Hochberg FDR procedure.\n",
    "    _, corrected, _, _ = multipletests(pvals.values, method='fdr_bh')\n",
    "    overlap_df['corrected_pvalue'] = corrected\n",
    "    return overlap_df\n",
    "\n",
    "def unshared_series(df, shared_index):\n",
    "    unshared_index = set(df.index.values) - set(shared_index)\n",
    "    return df.loc[unshared_index, :].genes\n",
    "\n",
    "def partition_shared(overlap_df, inputs, **kwargs):\n",
    "    \"\"\"\n",
    "    Partitions the gene modules into three data series:\n",
    "    * A shared data series for gene modules with significant\n",
    "      overlap\n",
    "    * Unshared BRCA data series\n",
    "    * Unshared OV data series\n",
    "    The shared data series has multi-index (`BRCA`, `OV`).\n",
    "    The unshared data series have index `Module`.\n",
    "    Each data series row has module gene set values.\n",
    "    \n",
    "    :param overlap_df: the input data frame is the BRCA x OV\n",
    "      module cartesian cross-product augmented with a\n",
    "      pair-wise overlap *corrected_pvalue*\n",
    "    :param inputs: the {name: <data frame>} inputs\n",
    "    :option cutoff: the corrected p-value cutoff value which\n",
    "      determines a shared module (default .01)\n",
    "    :return the {'shared': <series>, 'unshared': {name: <series>}}\n",
    "      data series dictionary for each *name* in inputs\n",
    "    \"\"\"\n",
    "    # The cut-off value.\n",
    "    cutoff = kwargs.get('cutoff', .01)\n",
    "    # The shared gene modules have corrected p-value < cutoff\n",
    "    criterion = overlap_df['corrected_pvalue'].lt(cutoff)\n",
    "    shared_df = overlap_df.loc[criterion]\n",
    "    # TODO - partition unshared\n",
    "    brca_only_ds = None\n",
    "    ov_only_ds = None\n",
    "    #brca_only_idx = overlap.index.droplevel('OV').difference(brca_shared.index).values\n",
    "    #brca_df.loc[:, ['Nodes in Module', 'Node List']]\n",
    "    brca_shared_genes = shared_df['BRCA Genes'].values\n",
    "    ov_shared_genes = shared_df['OV Genes'].values\n",
    "    merged_genes = [set(brca_shared_genes[i]) | set(ov_shared_genes[i])\n",
    "                    for i in range(len(ov_shared_genes))]\n",
    "    merged_df = shared_df.assign(merged_genes=merged_genes)\n",
    "    shared_ds = merged_df.merged_genes\n",
    "    shared_idx_values = [set(values)\n",
    "                         for values in zip(*shared_ds.index.values)]\n",
    "    shared_idx_names = shared_ds.index.names\n",
    "    shared_idx_dict = {name: shared_idx_values[i]\n",
    "                       for i, name in enumerate(shared_idx_names)}\n",
    "    unshared = {name: unshared_series(df, shared_idx_dict[name])\n",
    "                for name, df in inputs.items()}\n",
    "    return dict(shared=shared_ds, unshared=unshared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_overlap(n, inputs, max_len=None):\n",
    "    \"\"\"\n",
    "    Performs pair-wise overlap analysis on the given cluster\n",
    "    data frames.\n",
    "    \n",
    "    :param n: the background gene count\n",
    "    :param inputs: the {name: data frame} inputs dictionary\n",
    "    :option max_len: option specifies an upper bound on the\n",
    "      number of modules to be included in the overlap from\n",
    "      each cancer type in the overlap (see filter_on_module_size) \n",
    "    :return the {'shared': <series>, 'unshared': {name: <series>}}\n",
    "      data series dictionary for each *name* in inputs\n",
    "    \"\"\"\n",
    "    # Select the largest modules.\n",
    "    filtered = filter_on_module_size(inputs, max_len=max_len)\n",
    "    # Prep pair-wise analysis by taking the cartesian product\n",
    "    # of the two filtered data frames renamed with unique columns.\n",
    "    sliced = {name: slice_on_node_list(name, df) for name, df in inputs.items()}\n",
    "    cross_df = cartesian(*sliced.values())\n",
    "    overlap_df = append_overlap(n, cross_df)\n",
    "    return partition_shared(overlap_df, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_parsers = {\n",
    "    'ReactomePathway': lambda p: p,\n",
    "    'RatioOfProteinInPathway': float,\n",
    "    'NumberOfProteinInPathway': int,\n",
    "    'ProteinFromGeneSet': int,\n",
    "    'P-value': float,\n",
    "    'FDR': float,\n",
    "    'HitGenes': lambda s: s.split(',')\n",
    "}\n",
    "\n",
    "# Perform pathway enrichment analysis on the given gene list or set.\n",
    "# Returns the result data frame.\n",
    "def enrich(genes):\n",
    "    data = ','.join(genes)\n",
    "    # Perform the Reactome enrichment analysis.\n",
    "    resp = requests.post(get_fi_url('ReactomePathwayEnrichment'), json=data)\n",
    "    # Return the data frames.\n",
    "    return parse_fi_table_response(resp, enrichment_parsers, index='ReactomePathway')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the BRCA cohort for analysis.\n",
    "# This takes a while.\n",
    "brca_df = prepare('BRCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Result*: Cytoscape displays the BRCA FI network\n",
    "and clustered gene modules table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the OV cohort for analysis.\n",
    "# This takes a while.\n",
    "ov_df = prepare('OV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Result*: Cytoscape displays the OV FI network\n",
    "and clustered gene modules table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of background genes N is the Reactome FI\n",
    "# network gene size.\n",
    "BACKGROUND_GENE_CNT = 12283\n",
    "\n",
    "# The analysis input.\n",
    "inputs = {'BRCA': brca_df, 'OV': ov_df} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover modules with significant overlap.\n",
    "partition = analyse_overlap(BACKGROUND_GENE_CNT, inputs, max_len=20)\n",
    "shared_ds = partition['shared']\n",
    "brca_only_ds = partition['unshared']['BRCA']\n",
    "ov_only_ds = partition['unshared']['OV']\n",
    "# print(summary counts.)\n",
    "print(\"Cluster BRCA module count: %d\" % len(brca_df))\n",
    "print(\"Cluster OV module count: %d\" % len(ov_df))\n",
    "print(\"Shared module pairs count: %d\" % len(shared_ds))\n",
    "print(\"Unshared BRCA module count: %d\" % len(brca_only_ds))\n",
    "print(\"Unshared OV module count: %d\" % len(ov_only_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Reactome pathways.\n",
    "resp = requests.get(get_fi_url('pathwayTree'))\n",
    "reactome_tree = resp.json()['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Result*: Reactome heirarchy displayed in the Cytoscape Control Panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform pathway enrichment on the shared gene modules.\n",
    "enrichments = [enrich(gs) for gs in shared_ds.values]\n",
    "# Select the pathway (as index) and FDR where FDR < .001\n",
    "filtered = [e.FDR.loc[e.FDR.lt(.001)] for e in enrichments]\n",
    "# Collect all significant shared pathways.\n",
    "enriched = pd.concat(filtered).index.values\n",
    "print(\"Significant enriched pathway count: %d\" % enriched.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Expected Result*: Enrichment results are successively displayed in the Cytoscape Table Panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Perform pathway enrichment on the unshared BRCA gene modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Export the diagram for one pathway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Move doc cells below to appropriate steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(cf. User Guide\n",
    "[Explore Pathways](http://wiki.reactome.org/index.php?title=ReactomeFIViz&redirect=no#Explore_Reactome_Pathways)\n",
    "step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(cf. User Guide\n",
    "[Enrichment Analysis](http://wiki.reactome.org/index.php?title=ReactomeFIViz&redirect=no#Pathway_Enrichment_Analysis)\n",
    "step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(cf. User Guide\n",
    "[Mutation Analysis](http://wiki.reactome.org/index.php?title=ReactomeFIViz&redirect=no#Gene_Set.2FMutation_Analysis)\n",
    "step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
